## Big O of Quicksort

퀵 정령의 시간 및 공간 복잡도

| Time Complexity( Best ) | Time Complexity( Average ) | Time Complexity( Worst ) | Space Complexity |          
|:-----------------------:|:--------------------------:|:------------------------:|:----------------:|
|    **O( n log n )**     |      **O( n log n )**      |       **O( n2 )**        |  **O( log n )**  |


- 최상의 경우에는 합병 정렬과 시간 복잡도가 같다

---

### Time Complexity( 시간 복잡도 ) : Best Case

- 합병 정렬처럼 n( 배열의 길이 )이 늘어나면 밑이 2 인 log n 의 분해가 수행된다
  - ( pivot point 인 애들을 제외하고 작은 배열로 쪼개기 때문에...)


- 만약, [ 8 , 5 , 6 , 1 , 3 , 7 , 2 , 4 , 12 , 13 , 14 , 11 , 9 , 15 , 10 ] 이라는 배열이 있다고 가정했을 때,
  1. 1 번 쪼갤시( 재귀호출 ) 
     - pivot : **8**
     - left : [ 4 , 5 , 6 , 1 , 3 , 7 , 2]
     - right : [ 12 , 13 , 14 , 11 , 9 , 15 , 10 ]
  2. 2 번 쪼갤시( 재귀 호출 )
     - pivot : 4
     - left : [ 1 , 3 , 2 ]
     - right : [ 5 , 6 , 7 ]
     - ...
     - pivot : 12
     - left : [ 11 , 9 , 10 ]
     - right : [ 13 , 14 , 15 ]
  3. 3 번 쪼갤시( 재귀 호출 )
     - pivot : 1
     - left : []
     - right : [ 3 , 2 ]
     - ...
     - pivot : 5
     - left : []
     - right : [ 6 , 7 ]
     - ...
     - pivot : 11
     - left : [ 9 , 10 ]
     - right : []
     - ...
     - pivot : 13
     - left : []
     - right : [ 14 , 15 ]
  4. 4 번 쪼갤시( 재귀 호출 )
     - pivot : 3
     - left : [ 2 ]
     - right : []
     - ...
     - pivot : 6
     - left : []
     - right : [ 7 ]
     - ...
     - pivot : 9
     - left : []
     - right : [ 10 ]
     - ...
     - pivot : 14
     - left : []
     - right : [ 15 ]


- **O( log n )** decomposition


- 즉, 위처럼 2의 배수만큼 분해가 수행되는 패턴을 볼 수 있다


- 즉, 요소가 더 많을경우, 32개가 있을 경우에는 다섯 번 분해를 해야한다
  - ( 이 경우가 최상의 케이스이고 , 최악의 케이스도 존재한다 )


- 64 개의 요소라면? 여섯 번 분해해야 한다( **log n** 비율로 늘어난다 )
  - 하지만 각각 분해하는 단계마다 **O( n )** 번의 비교를 수행해야 한다
  - **O( n )** comparisons per decomposition


- pivot( swapIdx )을 찾을때, 이현상이 벌어진다
  - pivot 을 찾을때, 다른요소와 한번 비교한다


즉, 따라서 **O( n log n )** 이 성립 된다


( 합병 정렬과 매우 유사 )

---

### Time Complexity( 시간 복잡도 ) : Worst Case

- 현재의 알고리즘에서 pivot 함수는 언제나 첫 번째 항목을 pivot 으로 선택한다


- 데이터가 거의 정렬되어 있을 경우 문제가 된다
  - 현재 quick 정렬의 가장 나쁜 케이스다


- 만약, [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 ] 이라는 배열이 있다고 가정했을 때,
  1. 1 번 쪼갤시( 재귀호출 )
     - pivot : **1**
     - left : []
     - right : [ 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 ]
  2. 2 번 쪼갤시( 재귀호출 )
     - pivot : **2**
     - left : []
     - right : [ 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 ]
  3. 3 번 쪼갤시( 재귀호출 )
     - pivot : **3**
     - left : []
     - right : [ 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 ]    


- **O( n )** decomposition


- 이런식으로 분해를 거칠때마다 pivot 으로 정한 항목하나씩밖에 얻을 수 없다
  - 각각에 대해 모두 쪼개야하니 **O( n )** 분해가 된다
  - 또한, 각각 분해하는 단계마다 **O( n )** 번의 비교를 수행해야 한다
  - **O( n )** comparisons per decomposition


- 즉, **O( n^2 )** 라는 결과가 초래된다


- 따라서, pivot 을 고를 때, 매번 작은 el 만 선택하거나, 가장 큰 el 만 선택할 때 문제가 발생한다


- 만약, 이 문제를 고치려면, 적어도 정렬된 배열을 다루고 있을 경우, 
  - pivot 을 첫 번째 el 로 고정하지말고, 무엇이든 무작위 el 을 pivot 으로 정하면 된다
  - 무엇을 선택하든 중요하지 않다.
  - 무작위로 선택하거나, 매번 배열 중간에 있는 el 을 선택하는 것이다


- 이렇게 할 경우 정렬된 배열이라도, 문제를 피할 수 있다


- 물론 중간에 있는 요소를 고르고, 배열이 정렬되지 않고, 무작위 순서일 경우에도 언제나 최솟값을 고르게 될 가능성은 계속 존재한다


- 즉, 알고리즘의 작동방식으로 인해 최악의 케이스를 항상 피할수는 없다
  - ( 반복적으로 최솟값이나 최댓값을 pivot 으로 정하면 n^2 시간이 된다 )


- 다만, 최솟값이나 최댓값을 계속 선택할 가능성을 피할 수 있도록 최선을 다할 수 있다
  - ( 매번 첫 번째 or 마지막 요소를 선택하는 대신 무작위 수나 중간값을 선택하는 것 )